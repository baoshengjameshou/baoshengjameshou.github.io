---
layout: default
---

![James](images/HOU_circle.jpg)

I'm a PhD student in the field of Human-Computer Interaction (HCI), part of the [GEMINI](https://gemini-erc.eu/){:target="_blank"} project team at Lancaster University, supervised by [Prof. Hans Gellersen](https://www.lancaster.ac.uk/scc/about-us/people/hans-gellersen){:target="_blank"}. In GEMINI, we investigate the coordination of eye, head and body to design multimodal interfaces that 
<!-- more accurately capture the dynamic relationship between gaze and movement. Our goal is to enable users to  -->
better reflect the interplay of gaze and movement, and that let users 
interact more naturally in extended reality (XR), using their eyes and body in concert.

In my research, I apply machine learning (ML) and signal processing to model human behaviour as context for interaction, with a focus on developing novel eye-head-based interaction techniques. I aspire to a future in which ML-enabled devices enhance human capacities, interfacing in intuitively human ways.



<!-- > [<u>CV</u>](docs/resume.pdf){:target="_blank"}<br>
> [<u>Google Scholar</u>](https://scholar.google.com/citations?user=hwPzzQcAAAAJ&hl=en){:target="_blank"}<br>
> [<u>LinkedIn</u>](https://uk.linkedin.com/in/baosheng-james-hou-420931217){:target="_blank"}<br>
> [<u>Twitter</u>](https://twitter.com/JamesBHou){:target="_blank"}<br>
> [<u>Email</u>](mailto:b.hou2@lancaster.ac.uk){:target="_blank"}<br> -->

# Biography
Baosheng, also known as James, has a background in biomedical engineering ([<img src="images/pdfLogo.png" alt="pdf logo" class="responsive-image">](docs/CV.pdf){:target="_blank"} [CV](docs/CV.pdf){:target="_blank"}). He earned his Bachelor’s from the University of Auckland, modeling the human vocal tract's fluid dynamics under [Prof. Richard Clarke](https://profiles.auckland.ac.nz/rj-clarke){:target="_blank"} and [Prof. John Cater](https://www.teaomarama.auckland.ac.nz/project/john-cater/){:target="_blank"}. He interned at the Auckland Bioengineering Institute, using machine learning to predict soft tissue deformation for cancer imaging under [Dr. Duane Malcolm](https://www.flowx.io/about/){:target="_blank"}, and evaluated motion capture technologies for the shoulder complex, supervised by [Dr. Kumar Mithraratne](https://scholar.google.co.nz/citations?user=jJUQmIsAAAAJ&hl=en){:target="_blank" } and [Dr. Ted Yeung](https://profiles.auckland.ac.nz/ted-yeung){:target="_blank"}.

James completed his Master’s at the Technical University of Denmark (DTU), researching hybrid brain-computer interfaces under [Prof. Sadasivan Puthusserypady](https://orbit.dtu.dk/en/persons/sadasivan-puthusserypady){:target="_blank"} and [Prof. John Paulin Hansen](https://orbit.dtu.dk/en/persons/john-paulin-hansen){:target="_blank"}, their [paper](https://dl.acm.org/doi/abs/10.1145/3379157.3388932){:target="_blank"} was given the Best Paper Award. He also contributed as a bioinformatics programmer on a gold medal-winning [iGEM](https://igem.org/){:target="_blank"} [team](https://2016.igem.org/Team:DTU-Denmark){:target="_blank"}, advised by [Prof. Christopher Workman](https://scholar.google.com/citations?user=8sUv6OkAAAAJ&hl=en){:target="_blank"}. 

After his MSc., James worked as a research assistant at DTU, led by [Dr. Fiona Bríd Mulvey](https://orbit.dtu.dk/en/persons/fiona-b-mulvey){:target="_blank"} and [Prof. Per Bækgaard](https://orbit.dtu.dk/en/persons/per-b%C3%A6kgaard){:target="_blank"}, and in collaboration with occupational therapists, he helped develop a smart visual aid as XR headset for visually imparied patients.  Currently, as a PhD student in [Prof. Hans Gellersen](https://www.lancaster.ac.uk/scc/about-us/people/hans-gellersen){:target="_blank"}'s lab at Lancaster University, he applies machine learning and signal processing to develop classifiers for eye-head movements. During his PhD, he interned at Google AR with [Dr. Mar Gonzalez-Franco](https://margonzalezfranco.github.io/){:target="_blank"} and [Lucy Abramyan](https://www.linkedin.com/in/lucyabramyan){:target="_blank"}.

Using an experimental approach, James explores various interfacing technologies, including eye tracking, virtual reality and XR headsets, EOG glasses, and EEG. And has co-authored publications in _CHI_, _INTERACT_, _ETRA_, and _COGAIN_. In James' diverse projects and interdisciplinary endeavors, a consistent theme prevails: harnessing technology and the power of computational modelling to enhance the lives of people.

